[{"authors":null,"categories":null,"content":"Yosuke Shinya is a research engineer in computer vision and deep learning, especially in object detection and image generation. He is a senior researcher at PinAI (formerly SenseTime Japan). He has received the Award of the Minister of State for Science and Technology Policy (at the 50th Japan Student Science Award), OpenMMLab Contributor of the Year Award 2021, and Papers with Code Top Contributor Award.\n進矢陽介：物体検出や画像生成を中心としたコンピュータビジョンの研究開発に従事。 2014年東京大学大学院情報理工学系研究科修士課程修了。 三菱電機株式会社、株式会社デンソーを経て、2024年に株式会社センスタイムジャパン（現：株式会社ピンエーアイテクノロジー）に入社。 主な受賞歴に、第50回日本学生科学賞 科学技術政策担当大臣賞、OpenMMLab Contributor of the Year Award 2021、Papers with Code Top Contributor Award。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1757770395,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Yosuke Shinya is a research engineer in computer vision and deep learning, especially in object detection and image generation. He is a senior researcher at PinAI (formerly SenseTime Japan). He","tags":null,"title":"Yosuke Shinya","type":"authors"},{"authors":["Yosuke Shinya","Kenichi Yoneji","Akihiro Tsukada","Tatsuya Harada"],"categories":[],"content":"","date":1702425600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718735577,"objectID":"201289f1a61b6aa4538260735e314bdd","permalink":"https://shinya7y.github.io/publication/3dlighter-shinya-sa-2023/","publishdate":"2023-09-28T17:25:10.551554Z","relpermalink":"/publication/3dlighter-shinya-sa-2023/","section":"publication","summary":"We present a novel approach to generate emissive textures for luminous objects, using direct 3D supervision from a 3D model dataset. To this end, we construct Emissive Objaverse, a dataset based on the recently proposed Objaverse dataset, and propose 3D Lighter, a method using neural fields with generative latent optimization.","tags":[],"title":"3D Lighter: Learning to Generate Emissive Textures","type":"publication"},{"authors":["Yosuke Shinya"],"categories":[],"content":"","date":1690156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695923512,"objectID":"5e47bbb60b757bf77d27a782ca17f361","permalink":"https://shinya7y.github.io/publication/bandre-shinya-mva-2023/","publishdate":"2023-07-10T13:55:25.697243Z","relpermalink":"/publication/bandre-shinya-mva-2023/","section":"publication","summary":"Scale-wise evaluation of object detectors is important for real-world applications. However, existing metrics are either coarse or not sufficiently reliable. In this paper, we propose novel scale-wise metrics that strike a balance between fineness and reliability, using a filter bank consisting of triangular and trapezoidal band-pass filters. We conduct experiments with two methods on two datasets and show that the proposed metrics can highlight the differences between the methods and between the datasets.","tags":[],"title":"BandRe: Rethinking Band-Pass Filters for Scale-Wise Object Detection Evaluation","type":"publication"},{"authors":["Yuki Kondo","Norimichi Ukita","Takayuki Yamaguchi","Hao-Yu Hou","Mu-Yi Shen","Chia-Chi Hsu","En-Ming Huang","Yu-Chen Huang","Yu-Cheng Xia","Chien-Yao Wang","Chun-Yi Lee","Da Huo","Marc A. Kastner","Tingwei Liu","Yasutomo Kawanishi","Takatsugu Hirayama","Takahiro Komamizu","Ichiro Ide","Yosuke Shinya","Xinyao Liu","Guang Liang","Syusuke Yasui"],"categories":[],"content":"","date":1690156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695923512,"objectID":"00ae5f9a031f3d62e029feedc5bf72b9","permalink":"https://shinya7y.github.io/publication/sod4sb-kondo-mva-2023/","publishdate":"2023-07-10T13:55:35.061963Z","relpermalink":"/publication/sod4sb-kondo-mva-2023/","section":"publication","summary":"Small Object Detection (SOD) is an important machine vision topic because (i) a variety of real-world applications require object detection for distant objects and (ii) SOD is a challenging task due to the noisy, blurred, and less-informative image appearances of small objects. This paper proposes a new SOD dataset consisting of 39,070 images including 137,121 bird instances, which is called the Small Object Detection for Spotting Birds (SOD4SB) dataset. The detail of the challenge with the SOD4SB dataset is introduced in this paper. In total, 223 participants joined this challenge. This paper briefly introduces the award-winning methods. The dataset, the baseline code, and the website for evaluation on the public testset are publicly available.","tags":[],"title":"MVA2023 Small Object Detection Challenge for Spotting Birds: Dataset, Methods, and Results","type":"publication"},{"authors":["Yosuke Shinya"],"categories":[],"content":"","date":1668988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691331303,"objectID":"af9629df4fb9bf9676bccb7b846afb22","permalink":"https://shinya7y.github.io/publication/usb-shinya-bmvc-2022/","publishdate":"2022-10-29T04:38:38.761521Z","relpermalink":"/publication/usb-shinya-bmvc-2022/","section":"publication","summary":"Benchmarks, such as COCO, play a crucial role in object detection. However, existing benchmarks are insufficient in scale variation, and their protocols are inadequate for fair comparison. In this paper, we introduce the Universal-Scale object detection Benchmark (USB). USB has variations in object scales and image domains by incorporating COCO with the recently proposed Waymo Open Dataset and Manga109-s dataset. To enable fair comparison and inclusive research, we propose training and evaluation protocols. They have multiple divisions for training epochs and evaluation image resolutions, like weight classes in sports, and compatibility across training protocols, like the backward compatibility of the Universal Serial Bus. Specifically, we request participants to report results with not only higher protocols (longer training) but also lower protocols (shorter training). Using the proposed benchmark and protocols, we conducted extensive experiments using 15 methods and found weaknesses of existing COCO-biased methods.","tags":[],"title":"USB: Universal-Scale Object Detection Benchmark","type":"publication"},{"authors":["Laurent Dillard","Yosuke Shinya","Taiji Suzuki"],"categories":[],"content":"","date":1599523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689004018,"objectID":"aa3a33d3a1cb207592c4ab0da9ab17da","permalink":"https://shinya7y.github.io/publication/momasp-dillard-bmvc-2020/","publishdate":"2022-10-29T04:38:50.716915Z","relpermalink":"/publication/momasp-dillard-bmvc-2020/","section":"publication","summary":"Deep Neural Networks (DNNs) have recently been achieving state-of-the-art performance on a variety of computer vision related tasks. However, their computational cost limits their ability to be implemented in embedded systems with restricted resources or strict latency constraints. Model compression has therefore been an active field of research to overcome this issue. Additionally, DNNs typically require massive amounts of labeled data to be trained. This represents a second limitation to their deployment. Domain Adaptation (DA) addresses this issue by allowing knowledge learned on one labeled source distribution to be transferred to a target distribution, possibly unlabeled. In this paper, we investigate on possible improvements of compression methods in DA setting. We focus on a compression method that was previously developed in the context of a single data distribution and show that, with a careful choice of data to use during compression and additional regularization terms directly related to DA objectives, it is possible to improve compression results. We also show that our method outperforms an existing compression method studied in the DA setting by a large margin for high compression rates. Although our work is based on one specific compression method, we also outline some general guidelines for improving compression in DA setting.","tags":[],"title":"Domain Adaptation Regularization for Spectral Pruning","type":"publication"},{"authors":["Yosuke Shinya","Edgar Simo-Serra","Taiji Suzuki"],"categories":[],"content":"","date":1572220800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689004018,"objectID":"a65ecfad891fb6c3c43166376f3fa39c","permalink":"https://shinya7y.github.io/publication/intrinsicdet-shinya-iccvw-2019/","publishdate":"2022-10-29T04:38:50.861161Z","relpermalink":"/publication/intrinsicdet-shinya-iccvw-2019/","section":"publication","summary":"ImageNet pre-training has been regarded as essential for training accurate object detectors for a long time. Recently, it has been shown that object detectors trained from randomly initialized weights can be on par with those fine-tuned from ImageNet pre-trained models. However, the effects of pre-training and the differences caused by pre-training are still not fully understood. In this paper, we analyze the eigenspectrum dynamics of the covariance matrix of each feature map in object detectors. Based on our analysis on ResNet-50, Faster R-CNN with FPN, and Mask R-CNN, we show that object detectors trained from ImageNet pre-trained models and those trained from scratch behave differently from each other even if both object detectors have similar accuracy. Furthermore, we propose a method for automatically determining the widths (the numbers of channels) of object detectors based on the eigenspectrum. We train Faster R-CNN with FPN from randomly initialized weights, and show that our method can reduce ~27% of the parameters of ResNet-50 without increasing Multiply-Accumulate operations and losing accuracy. Our results indicate that we should develop more appropriate methods for transferring knowledge from image classification to object detection (or other tasks).","tags":[],"title":"Understanding the Effects of Pre-Training for Object Detectors via Eigenspectrum","type":"publication"},{"authors":["Hideomi Tsunakawa","Yoshitaka Kameya","Hanju Lee","Yosuke Shinya","Naoki Mitsumoto"],"categories":[],"content":"","date":1563408e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689004018,"objectID":"c2cac71c36a88cfef625427aebaaf5a5","permalink":"https://shinya7y.github.io/publication/crp-tsunakawa-ijcnn-2019/","publishdate":"2022-10-29T04:38:51.002997Z","relpermalink":"/publication/crp-tsunakawa-ijcnn-2019/","section":"publication","summary":"Object detection is a widely-used computer vision task, in which we identify a bounding box around each object in an image and classify the object into one of pre-defined classes. Single Shot MultiBox Detector (SSD) is a real-time object detector based on a single convolutional neural network. SSD is popular and known for high speed and accuracy, but its black-box nature is not ignorable when it is applied to critical systems. In this paper, we propose Contrastive Relevance Propagation (CRP), an extension of Layer-wise Relevance Propagation (LRP) tailored for SSD. CRP can consistently deal with SSD's heterogeneous output, i.e. confidences for object classes and location offsets, and create a heatmap that highlights a crucial part of the input, which is not available with a standard use of LRP. By experiments with the Pascal VOC 2012 dataset, we confirmed the quality of heatmaps created by CRP, and with such heatmaps, we conducted a simple analysis on prediction errors made by SSD.","tags":[],"title":"Contrastive Relevance Propagation for Interpreting Predictions by a Single-Shot Object Detector","type":"publication"},{"authors":["Yoshihiro Sato","Yosuke Shinya","Bo Zheng","Takeshi Oishi","Katsushi Ikeuchi"],"categories":[],"content":"","date":1431993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667027831,"objectID":"6caf74bea802831ddb82b1d847e84d41","permalink":"https://shinya7y.github.io/publication/stoneip-sato-mva-2015/","publishdate":"2022-10-29T04:38:51.146587Z","relpermalink":"/publication/stoneip-sato-mva-2015/","section":"publication","summary":"High-quality modeling method is required for the virtual reconstruction of ruins using mixed reality. Stone floor is one of the important parts of the ruins. In order to render the stone floor realistically, it requires a high-quality model produced by excavation information. For the reconstruction of the lacked part of stone floor, shape modifying method while maintaining a shape characteristic and the distribution of the original is required. In this paper, we propose a shape-forming method to reconstruct the stone floor from excavated data by using Implicit Polynomial(IP). IP which is the implicit function curved surface can perform interpolation and blending easily.","tags":[],"title":"Modeling the Stone Floor Based on Excavation Information Using Implicit Polynomial","type":"publication"}]